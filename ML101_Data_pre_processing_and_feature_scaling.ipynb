{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranj10/ML101_Data_pre_processing_and_feature_scaling/blob/main/ML101_Data_pre_processing_and_feature_scaling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45e47f32",
      "metadata": {
        "id": "45e47f32"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9061d488",
      "metadata": {
        "id": "9061d488"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "619ee2a4",
      "metadata": {
        "id": "619ee2a4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a95fc74",
      "metadata": {
        "id": "0a95fc74"
      },
      "source": [
        "### Importing the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c843f73",
      "metadata": {
        "id": "6c843f73"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('Data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e4fb6cb",
      "metadata": {
        "id": "3e4fb6cb",
        "outputId": "8fe8b1d0-f7c8-437d-ec04-70daa9a18511"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Age</th>\n",
              "      <th>Salary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>France</td>\n",
              "      <td>44.0</td>\n",
              "      <td>72000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Spain</td>\n",
              "      <td>27.0</td>\n",
              "      <td>48000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Germany</td>\n",
              "      <td>30.0</td>\n",
              "      <td>54000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Spain</td>\n",
              "      <td>38.0</td>\n",
              "      <td>61000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Germany</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>France</td>\n",
              "      <td>35.0</td>\n",
              "      <td>58000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Spain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>France</td>\n",
              "      <td>48.0</td>\n",
              "      <td>79000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Germany</td>\n",
              "      <td>50.0</td>\n",
              "      <td>83000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>France</td>\n",
              "      <td>37.0</td>\n",
              "      <td>67000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Country   Age   Salary Purchased\n",
              "0   France  44.0  72000.0        No\n",
              "1    Spain  27.0  48000.0       Yes\n",
              "2  Germany  30.0  54000.0        No\n",
              "3    Spain  38.0  61000.0        No\n",
              "4  Germany  40.0      NaN       Yes\n",
              "5   France  35.0  58000.0       Yes\n",
              "6    Spain   NaN  52000.0        No\n",
              "7   France  48.0  79000.0       Yes\n",
              "8  Germany  50.0  83000.0        No\n",
              "9   France  37.0  67000.0       Yes"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de0f97f0",
      "metadata": {
        "id": "de0f97f0"
      },
      "source": [
        "### Selecting Independent variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3c62415",
      "metadata": {
        "id": "f3c62415"
      },
      "outputs": [],
      "source": [
        "X = dataset.iloc[:, :-1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3747313",
      "metadata": {
        "id": "f3747313",
        "outputId": "c07ce1a7-cd0f-4b77-bb01-d29ab862996b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['France', 44.0, 72000.0],\n",
              "       ['Spain', 27.0, 48000.0],\n",
              "       ['Germany', 30.0, 54000.0],\n",
              "       ['Spain', 38.0, 61000.0],\n",
              "       ['Germany', 40.0, nan],\n",
              "       ['France', 35.0, 58000.0],\n",
              "       ['Spain', nan, 52000.0],\n",
              "       ['France', 48.0, 79000.0],\n",
              "       ['Germany', 50.0, 83000.0],\n",
              "       ['France', 37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6302887",
      "metadata": {
        "id": "a6302887"
      },
      "source": [
        "### Selecting Dependent variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed2b5012",
      "metadata": {
        "id": "ed2b5012"
      },
      "outputs": [],
      "source": [
        "y = dataset.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb573fe",
      "metadata": {
        "id": "3eb573fe",
        "outputId": "b1729236-1d48-494a-8498-de7c3fce55c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "# Taking care of missing data\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(X[:, 1:3])\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca15cd09",
      "metadata": {
        "id": "ca15cd09",
        "outputId": "decdd8a1-2fde-4eef-efaf-43860a14ff93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f44f8f6d",
      "metadata": {
        "id": "f44f8f6d"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c16930cb",
      "metadata": {
        "id": "c16930cb"
      },
      "source": [
        "## 2.1: Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dee0ded8",
      "metadata": {
        "id": "dee0ded8"
      },
      "source": [
        "If we convert it into France, Spain and Germany into 0, 1 & 2. ML models may take it as a numerical order.\n",
        "ML model may think that order matters.\n",
        "However, there is no relationship. There will be some misinterpreted correlation.\n",
        "Onehot encoding convert this country column into three columns, using binary vectors.\n",
        "Hence, there will be no numerical order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23dd3300",
      "metadata": {
        "id": "23dd3300",
        "outputId": "6b99527a-9369-4228-f05f-45b4f078e158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.compose import ColumnTransformer # Importing class column transform\n",
        "from sklearn.preprocessing import OneHotEncoder # import class OneHotEncoder\n",
        "\n",
        "# create object ct\n",
        "# Call class ColumnTransformer\n",
        "# First call transformers to tell which tranformation we have to do and which column we have to use\n",
        "# encoder means we want encoding and then what type of encoding means OneHotEncoder\n",
        "# remainder will tell us to keep the column where we will not apply the transformation\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "\n",
        "# using fit_transform method to do onehotencoding\n",
        "# It does not give result into numpy array\n",
        "X = np.array(ct.fit_transform(X))\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f960e5c",
      "metadata": {
        "id": "2f960e5c"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fd1cf04",
      "metadata": {
        "id": "8fd1cf04",
        "outputId": "8ec0cb8b-a83f-4120-c8bb-7dae293d88bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder # importing labelencoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c985c2d9",
      "metadata": {
        "id": "c985c2d9"
      },
      "source": [
        "#### When should we do feature scaling? Is it before or after splitting the dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23491671",
      "metadata": {
        "id": "23491671"
      },
      "source": [
        "Feature scaling should be done after splitting the dataset. For example, if we do before mean and standard deviation will be from all the values including the one's from test set. Test set is not supposed to have information from training set. If we use all values for feature scaling, it would lead to information leakage on the test set. Test set is supposed to be new data or new observation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0537fce9",
      "metadata": {
        "id": "0537fce9"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c56f46",
      "metadata": {
        "id": "f6c56f46"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
        "# test_size 0.2 means 20 percent of data will be in test\n",
        "# random_State = 1 means, we will get the same information everytime as we are randomly splitting the data.\n",
        "# random_state means we are just fixing the seet here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef3e6fa",
      "metadata": {
        "id": "8ef3e6fa",
        "outputId": "a1d219f7-f884-409c-820e-da195543227e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
              "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
              "       [1.0, 0.0, 0.0, 44.0, 72000.0],\n",
              "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
              "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
              "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
              "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
              "       [1.0, 0.0, 0.0, 35.0, 58000.0]], dtype=object)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730f8526",
      "metadata": {
        "id": "730f8526",
        "outputId": "d60e7c5c-e905-45b0-b43b-9691aab1bcbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, 30.0, 54000.0],\n",
              "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47437d8e",
      "metadata": {
        "id": "47437d8e",
        "outputId": "13455d90-b95a-4b86-d3bd-7e40fbcdc687"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 1, 0, 1])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af13cc83",
      "metadata": {
        "id": "af13cc83",
        "outputId": "e610a45c-00db-4e42-ffb3-be24b601b02f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b30b91",
      "metadata": {
        "id": "f1b30b91"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42747576",
      "metadata": {
        "id": "42747576"
      },
      "source": [
        "#### Standardization\n",
        "$X = \\frac{Xi - {X}_{mean}} {SD}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebbf38ee",
      "metadata": {
        "id": "ebbf38ee"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "# fit will calculate mean and sd\n",
        "# transform will calculate standardized value\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "\n",
        "# Here we will use only transform method as test data set is like new dataset.\n",
        "# Hence, we have to use same scalar that was used for training datset because ML model will be trained with particular scaler\n",
        "# using fit method will add new scalar\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f90373d3",
      "metadata": {
        "id": "f90373d3",
        "outputId": "108c137c-b942-48bc-d1a6-3d418134f2bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.0, 0.0, 1.0, -0.1915918438457856, -1.0781259408412427],\n",
              "       [0.0, 1.0, 0.0, -0.014117293757057902, -0.07013167641635401],\n",
              "       [1.0, 0.0, 0.0, 0.5667085065333239, 0.6335624327104546],\n",
              "       [0.0, 0.0, 1.0, -0.3045301939022488, -0.30786617274297895],\n",
              "       [0.0, 0.0, 1.0, -1.901801144700799, -1.4204636155515822],\n",
              "       [1.0, 0.0, 0.0, 1.1475343068237056, 1.2326533634535488],\n",
              "       [0.0, 1.0, 0.0, 1.4379472069688966, 1.5749910381638883],\n",
              "       [1.0, 0.0, 0.0, -0.7401495441200352, -0.5646194287757336]],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87b8ebc8",
      "metadata": {
        "id": "87b8ebc8",
        "outputId": "6cc2060a-0dde-460a-9f47-69e8d73837a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, -1.4661817944830127, -0.9069571034860731],\n",
              "       [1.0, 0.0, 0.0, -0.44973664397484425, 0.20564033932253029]],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa8dcebb",
      "metadata": {
        "id": "aa8dcebb"
      },
      "source": [
        "#### Min-max scaler\n",
        "$X = \\frac{{X}_{i} - min(X)} {max(X) - min(X)}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e12629",
      "metadata": {
        "id": "06e12629"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler()\n",
        "\n",
        "# fit will calculate mean and sd\n",
        "# transform will calculate standardized value\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "\n",
        "# Here we will use only transform method as test data set is like new dataset.\n",
        "# Hence, we have to use same scalar that was used for training datset because ML model will be trained with particular scaler\n",
        "# using fit method will add new scalar\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0eedeff",
      "metadata": {
        "id": "e0eedeff",
        "outputId": "690adb03-1cf9-4ada-a4a3-c2d8243bbd39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.0, 0.0, 1.0, 0.5120772946859904, 0.11428571428571427],\n",
              "       [0.0, 1.0, 0.0, 0.5652173913043479, 0.4507936507936508],\n",
              "       [1.0, 0.0, 0.0, 0.7391304347826088, 0.6857142857142856],\n",
              "       [0.0, 0.0, 1.0, 0.47826086956521746, 0.37142857142857133],\n",
              "       [0.0, 0.0, 1.0, 0.0, 0.0],\n",
              "       [1.0, 0.0, 0.0, 0.9130434782608696, 0.8857142857142857],\n",
              "       [0.0, 1.0, 0.0, 1.0, 0.9999999999999998],\n",
              "       [1.0, 0.0, 0.0, 0.34782608695652184, 0.28571428571428564]],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4390fd6f",
      "metadata": {
        "id": "4390fd6f",
        "outputId": "6a61f6ae-021a-46a0-e951-3a8cd36250f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, 0.13043478260869568, 0.17142857142857137],\n",
              "       [1.0, 0.0, 0.0, 0.4347826086956522, 0.5428571428571427]],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fa082fa",
      "metadata": {
        "id": "7fa082fa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}